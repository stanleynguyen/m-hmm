{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hmm import SUTDHMM\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Estimate the emission parameters from the training set using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish training for EN\n",
      "Finished: EN\n",
      "Language: EN\n",
      "\n",
      "#Entity in gold data: 226\n",
      "#Entity in prediction: 706\n",
      "\n",
      "#Correct Entity : 133\n",
      "Entity  precision: 0.1884\n",
      "Entity  recall: 0.5885\n",
      "Entity  F: 0.2854\n",
      "\n",
      "#Correct Sentiment : 45\n",
      "Sentiment  precision: 0.0637\n",
      "Sentiment  recall: 0.1991\n",
      "Sentiment  F: 0.0966\n",
      "\n",
      "----------------------\n",
      "Finish training for SG\n",
      "Finished: SG\n",
      "Language: SG\n",
      "\n",
      "#Entity in gold data: 1382\n",
      "#Entity in prediction: 2764\n",
      "\n",
      "#Correct Entity : 511\n",
      "Entity  precision: 0.1849\n",
      "Entity  recall: 0.3698\n",
      "Entity  F: 0.2465\n",
      "\n",
      "#Correct Sentiment : 272\n",
      "Sentiment  precision: 0.0984\n",
      "Sentiment  recall: 0.1968\n",
      "Sentiment  F: 0.1312\n",
      "\n",
      "----------------------\n",
      "Finish training for CN\n",
      "Finished: CN\n",
      "Language: CN\n",
      "\n",
      "#Entity in gold data: 362\n",
      "#Entity in prediction: 1688\n",
      "\n",
      "#Correct Entity : 114\n",
      "Entity  precision: 0.0675\n",
      "Entity  recall: 0.3149\n",
      "Entity  F: 0.1112\n",
      "\n",
      "#Correct Sentiment : 71\n",
      "Sentiment  precision: 0.0421\n",
      "Sentiment  recall: 0.1961\n",
      "Sentiment  F: 0.0693\n",
      "\n",
      "----------------------\n",
      "Finish training for FR\n",
      "Finished: FR\n",
      "Language: FR\n",
      "\n",
      "#Entity in gold data: 223\n",
      "#Entity in prediction: 691\n",
      "\n",
      "#Correct Entity : 174\n",
      "Entity  precision: 0.2518\n",
      "Entity  recall: 0.7803\n",
      "Entity  F: 0.3807\n",
      "\n",
      "#Correct Sentiment : 65\n",
      "Sentiment  precision: 0.0941\n",
      "Sentiment  recall: 0.2915\n",
      "Sentiment  F: 0.1422\n",
      "\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "from hmm import SUTDHMM\n",
    "languages = ['EN', 'SG', 'CN', 'FR']\n",
    "\n",
    "for l in languages:\n",
    "    model = SUTDHMM()\n",
    "    model.train(input_filename='./{}/train'.format(l))\n",
    "    print(\"Finish training for {}\".format(l))\n",
    "\n",
    "    with open(\"./{}/dev.in\".format(l)) as in_file, open(\"./{}/dev.p2.out\".format(l), 'w+') as out_file:\n",
    "        for line in in_file:\n",
    "            word = line.strip()\n",
    "            if (word == ''):\n",
    "                out_file.write(\"\\n\")\n",
    "            else:\n",
    "                out_file.write(\"{} {}\\n\".format(word, model.predict_label_using_emission(word)))\n",
    "    print(\"Finished: {}\".format(l))\n",
    "    \n",
    "    output = os.popen(\"python3 EvalScript/evalResult.py {0}/dev.out {0}/dev.p2.out\".format(l)).read()\n",
    "    print(\"Language: {}\".format(l))\n",
    "    print(output)\n",
    "    print(\"----------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
