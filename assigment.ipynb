{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Estimate the emission parameters from the training set using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class Emission:\n",
    "    def __init__(self):\n",
    "        self.emission_p = {}\n",
    "        self.y_count = {}\n",
    "        self.y_labels = []\n",
    "        self.x_given_y_count = {}\n",
    "        self.tokens_list = []\n",
    "        self.special_token = '#UNK#'\n",
    "    \n",
    "    def clean_data(self, k = 1):\n",
    "        token_freq = {}\n",
    "        for token in self.tokens_list:\n",
    "            if token[0] not in token_freq: \n",
    "                token_freq[token[0]] = 1\n",
    "            else:\n",
    "                token_freq[token[0]] += 1\n",
    "        for i in range(len(self.tokens_list)):\n",
    "            if token_freq[self.tokens_list[i][0]] < k:\n",
    "                self.tokens_list[i][0] = self.special_token\n",
    "        return self.tokens_list\n",
    "    \n",
    "    def train(self, tokens_list: list, k = 1, special_token = '#UNK#'):\n",
    "        self.tokens_list = tokens_list\n",
    "        self.special_token = special_token\n",
    "        self.clean_data(k)\n",
    "        self.y_count = {}\n",
    "        self.x_given_y_count = {} \n",
    "\n",
    "        for token in tokens_list:\n",
    "            if token[1] not in self.y_count:\n",
    "                self.y_count[token[1]] = 1\n",
    "                self.x_given_y_count[token[1]] = {}\n",
    "                self.x_given_y_count[token[1]][token[0]] = 1\n",
    "            else:\n",
    "                self.y_count[token[1]] += 1\n",
    "                if token[0] not in self.x_given_y_count[token[1]]:\n",
    "                    self.x_given_y_count[token[1]][token[0]] = 1\n",
    "                else:\n",
    "                    self.x_given_y_count[token[1]][token[0]] += 1\n",
    "\n",
    "        # calculate emission params\n",
    "        self.emission_p = copy.deepcopy(self.x_given_y_count)\n",
    "        for label in self.emission_p:\n",
    "            for word in self.emission_p[label]:\n",
    "                self.emission_p[label][word] = float(self.x_given_y_count[label][word]) / self.y_count[label]\n",
    "        self.y_labels = list(self.emission_p.keys())\n",
    "        return self.emission_p\n",
    "    \n",
    "    def predict(self, y: str, x: str):\n",
    "        x_inside = False\n",
    "        for token in self.tokens_list:\n",
    "            if token[0] == x:\n",
    "                x_inside = True\n",
    "                break\n",
    "\n",
    "        if not x_inside:\n",
    "            x = self.special_token\n",
    "\n",
    "        if x not in self.emission_p[y]:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.emission_p[y][x]\n",
    "        \n",
    "    def predict_tag(self, x: str):\n",
    "        score = 0.0\n",
    "        y_tag = None\n",
    "        for y in self.y_labels:\n",
    "            y_score = self.predict(y, x)\n",
    "            if y_score > score:\n",
    "                y_tag = y\n",
    "                score = y_score\n",
    "        return y_tag\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': {'a': 0.3333333333333333, 'b': 0.3333333333333333, 'c': 0.3333333333333333}, 'I': {'a': 1.0}}\n",
      "0.3333333333333333\n",
      "['O', 'I']\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "# Example ussage\n",
    "import os\n",
    "\n",
    "data = [['a', 'O'], ['b', 'O'], ['a', 'I'], ['c', 'O']]\n",
    "model = Emission()\n",
    "print(model.train(tokens_list=data))\n",
    "print(model.predict(y='O', x='b'))\n",
    "print(model.y_labels)\n",
    "print(model.predict_tag('a'))\n",
    "\n",
    "# with open('./EN/train') as train_file:\n",
    "#     read_data = train_file.read()\n",
    "#     read_data = os.linesep.join([s for s in read_data.splitlines() if s])\n",
    "#     data = list(map(lambda x: x.split(' '),read_data.split('\\n')))\n",
    "# emission_params(tokens_list=data, y='O', x='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify training set to replace words that appear less than k times with special token. Apply this to the emission parameters prediction function with k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "data = [['a', 'O'], ['b', 'O'], ['a', 'I'], ['c', 'O'], ['a', 'O']]\n",
    "model = Emission()\n",
    "model.train(tokens_list=data, k = 3)\n",
    "model.predict(y='O', x='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis system that produces the tag for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish training for EN\n",
      "Finished: EN\n",
      "Finish training for SG\n",
      "Finished: SG\n",
      "Finish training for CN\n",
      "Finished: CN\n",
      "Finish training for FR\n",
      "Finished: FR\n"
     ]
    }
   ],
   "source": [
    "languages = ['EN', 'SG', 'CN', 'FR']\n",
    "\n",
    "for l in languages:\n",
    "    model = Emission()\n",
    "    with open(\"./{}/train\".format(l)) as train_file:\n",
    "        read_data = train_file.read()\n",
    "        read_data = os.linesep.join([s for s in read_data.splitlines() if s])\n",
    "        data = list(map(lambda x: x.split(' '),read_data.split('\\n')))\n",
    "        model.train(tokens_list=data, k=3)\n",
    "    \n",
    "    print(\"Finish training for {}\".format(l))\n",
    "\n",
    "    with open(\"./{}/dev.in\".format(l)) as in_file, open(\"./{}/dev.p2.out\".format(l), 'w+') as out_file:\n",
    "        for line in in_file:\n",
    "            word = line.strip()\n",
    "            if (word == ''):\n",
    "                out_file.write(\"\\n\")\n",
    "            else:\n",
    "                out_file.write(\"{} {}\\n\".format(word, model.predict_tag(word)))\n",
    "    print(\"Finished: {}\".format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: EN\n",
      "\n",
      "#Entity in gold data: 226\n",
      "#Entity in prediction: 1201\n",
      "\n",
      "#Correct Entity : 165\n",
      "Entity  precision: 0.1374\n",
      "Entity  recall: 0.7301\n",
      "Entity  F: 0.2313\n",
      "\n",
      "#Correct Sentiment : 71\n",
      "Sentiment  precision: 0.0591\n",
      "Sentiment  recall: 0.3142\n",
      "Sentiment  F: 0.0995\n",
      "\n",
      "----------------------\n",
      "Language: SG\n",
      "\n",
      "#Entity in gold data: 1382\n",
      "#Entity in prediction: 6542\n",
      "\n",
      "#Correct Entity : 780\n",
      "Entity  precision: 0.1192\n",
      "Entity  recall: 0.5644\n",
      "Entity  F: 0.1969\n",
      "\n",
      "#Correct Sentiment : 311\n",
      "Sentiment  precision: 0.0475\n",
      "Sentiment  recall: 0.2250\n",
      "Sentiment  F: 0.0785\n",
      "\n",
      "----------------------\n",
      "Language: CN\n",
      "\n",
      "#Entity in gold data: 362\n",
      "#Entity in prediction: 3318\n",
      "\n",
      "#Correct Entity : 183\n",
      "Entity  precision: 0.0552\n",
      "Entity  recall: 0.5055\n",
      "Entity  F: 0.0995\n",
      "\n",
      "#Correct Sentiment : 57\n",
      "Sentiment  precision: 0.0172\n",
      "Sentiment  recall: 0.1575\n",
      "Sentiment  F: 0.0310\n",
      "\n",
      "----------------------\n",
      "Language: FR\n",
      "\n",
      "#Entity in gold data: 223\n",
      "#Entity in prediction: 1149\n",
      "\n",
      "#Correct Entity : 182\n",
      "Entity  precision: 0.1584\n",
      "Entity  recall: 0.8161\n",
      "Entity  F: 0.2653\n",
      "\n",
      "#Correct Sentiment : 68\n",
      "Sentiment  precision: 0.0592\n",
      "Sentiment  recall: 0.3049\n",
      "Sentiment  F: 0.0991\n",
      "\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "for l in languages:\n",
    "    output = os.popen(\"python3 EvalScript/evalResult.py {0}/dev.out {0}/dev.p2.out\".format(l)).read()\n",
    "    print(\"Language: {}\".format(l))\n",
    "    print(output)\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimates the transition parameters from the training set using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "def transition_params(ordered_labels_list: list):\n",
    "    count = {}\n",
    "    count_given = {} # 2 layer dictionary depth-0 key is the (i-1)-label, depth-1 key is the i-label\n",
    "    \n",
    "    # count frequency of all label and combinations of 2 labels in the dataset\n",
    "    for idx, label in enumerate(ordered_labels_list):\n",
    "        if label not in count:\n",
    "            count[label] = 1\n",
    "            count_given[label] = {}\n",
    "            if idx < len(ordered_labels_list) - 1:\n",
    "                next_label = ordered_labels_list[idx + 1]\n",
    "                count_given[label][next_label] = 1\n",
    "        else:\n",
    "            count[label] += 1\n",
    "            if idx < len(ordered_labels_list) - 1:\n",
    "                next_label = ordered_labels_list[idx + 1]\n",
    "                if next_label not in count_given[label]:\n",
    "                    count_given[label][next_label] = 1\n",
    "                else:\n",
    "                    count_given[label][next_label] += 1\n",
    "    \n",
    "    # calculate trans_params\n",
    "    trans_params = copy.deepcopy(count_given)\n",
    "    for given_label in trans_params:\n",
    "        for label in trans_params[given_label]:\n",
    "            trans_params[given_label][label] /= count[given_label]\n",
    "            \n",
    "    return trans_params\n",
    "\n",
    "def specific_transition_params(ordered_labels_list: list, y: str, y_given: str):\n",
    "    trans_params = transition_params(ordered_labels_list)\n",
    "    if y not in trans_params:\n",
    "        return 0;\n",
    "    elif y_given not in trans_params[y]:\n",
    "        return 0;\n",
    "    else:\n",
    "        return trans_params[y_given][y]\n",
    "    \n",
    "specific_transition_params(['a', 'b', 'b', 'c', 'b', 'a', 'd', 'h', 'b'], 'b', 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viterbi algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line string', (1, 0))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hey': {'I': 1.0}, 'I': {'was': 0.14285714285714285, 'met': 0.14285714285714285, 'hope': 0.14285714285714285, 'never': 0.14285714285714285, 'know': 0.14285714285714285, \"can't\": 0.2857142857142857}, 'was': {'doing': 0.5, 'nice': 0.5}, 'doing': {'just': 1.0}, 'just': {'fine': 1.0}, 'fine': {'before': 1.0}, 'before': {'I': 1.0}, 'met': {'you': 1.0}, 'you': {'Drink': 0.5, 'tell': 0.5}, 'Drink': {'too': 1.0}, 'too': {'much': 1.0}, 'much': {'and': 1.0}, 'and': {\"that's\": 1.0}, \"that's\": {'an': 1.0}, 'an': {'issue': 1.0}, 'issue': {'But': 1.0}, 'But': {\"I'm\": 0.5, 'I': 0.5}, \"I'm\": {'okay': 1.0}, 'okay': {'Hey,': 1.0}, 'Hey,': {'you': 1.0}, 'tell': {'your': 1.0}, 'your': {'friends': 0.5, 'heart': 0.5}, 'friends': {'it': 1.0}, 'it': {'was': 0.5, 'breaks': 0.5}, 'nice': {'to': 1.0}, 'to': {'meet': 0.5, 'the': 0.5}, 'meet': {'them': 1.0}, 'them': {'But': 0.5, 'Again': 0.5}, 'hope': {'I': 1.0}, 'never': {'see': 1.0}, 'see': {'them': 1.0}, 'Again': {'I': 1.0}, 'know': {'it': 1.0}, 'breaks': {'your': 1.0}, 'heart': {'Moved': 1.0}, 'Moved': {'to': 1.0}, 'the': {'city': 1.0}, 'city': {'in': 1.0}, 'in': {'a': 1.0}, 'a': {'broke-down': 0.5, 'hotel': 0.5}, 'broke-down': {'car': 1.0}, 'car': {'And': 1.0}, 'And': {'four': 0.5, 'I,': 0.5}, 'four': {'years,': 1.0}, 'years,': {'no': 1.0}, 'no': {'calls': 1.0}, 'calls': {'Now': 1.0}, 'Now': {\"you're\": 1.0}, \"you're\": {'looking': 1.0}, 'looking': {'pretty': 1.0}, 'pretty': {'in': 1.0}, 'hotel': {'bar': 1.0}, 'bar': {'And': 1.0}, 'I,': {'I,': 0.75, 'I': 0.25}, \"can't\": {'stop': 1.0}, 'stop': {'No,': 0.5}, 'No,': {'I,': 1.0}}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8c0a2e332aea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mAnd\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m \u001b[0mcan\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mNo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m \u001b[0mcan\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \"\"\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-8c0a2e332aea>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m          \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m viterbi(\"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "def viterbi(training_tokens: list, sentence: str):\n",
    "    sentence = sentence.split()\n",
    "    # sentence has both START and STOP words\n",
    "    cache = {}\n",
    "    y_predicted = []\n",
    "    trans_params = transition_params(sentence)\n",
    "    print(trans_params)\n",
    "    emission_params = emission_params_cache(training_tokens)\n",
    "    for k in range(len(sentence)-1):\n",
    "         pass\n",
    "    return result\n",
    "\n",
    "viterbi(\"\"\"\n",
    "Hey I was doing just fine before I met you\n",
    "Drink too much and that\\'s an issue\n",
    "But I\\'m okay\n",
    "Hey, you tell your friends it was nice to meet them\n",
    "But I hope I never see them\n",
    "Again\n",
    "I know it breaks your heart\n",
    "Moved to the city in a broke-down car\n",
    "And four years, no calls\n",
    "Now you're looking pretty in a hotel bar\n",
    "And I, I, I, I, I can't stop\n",
    "No, I, I, I, I, I can't stop\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
